{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sns.set(font_scale=2, style='whitegrid')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if os.path.abspath('..') not in sys.path:\n",
    "    sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from var_gp.vargp import VARGP\n",
    "from var_gp.datasets import SplitMNIST, PermutedMNIST\n",
    "from var_gp.train_utils import set_seeds, compute_acc_ent, compute_bwt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import os\n",
    "# from collections import defaultdict\n",
    "# \n",
    "## Parse the VCL experiments folder.\n",
    "# def parse_raw_vcl(path):\n",
    "#     results = defaultdict(dict)\n",
    "\n",
    "#     for exp in os.listdir(path):\n",
    "#         if not exp.startswith('nn_model'):\n",
    "#             continue\n",
    "\n",
    "#         kv = exp.split('_')\n",
    "#         layers = '_'.join([v.strip() for v in kv[kv.index('hidden') + 2].lstrip('[').rstrip(']').split(',')])\n",
    "#         coreset = kv[kv.index('coreset') + 2]\n",
    "#         seed = kv[kv.index('seed') + 1]\n",
    "\n",
    "#         results[f'vcl_{layers}_coreset_{coreset}'][seed] = np.load(f'{path}/{exp}/test_acc.npz')['acc']\n",
    "\n",
    "#     for seed in range(5):\n",
    "#         avg_acc = []\n",
    "#         acc_mat = results['vcl_100_100_coreset_100'][f'{seed + 1}']\n",
    "#         for i, row in enumerate(acc_mat):\n",
    "#             avg_acc.append(np.mean(row[:i + 1]))\n",
    "\n",
    "#         print('\\n'.join([str(v) for v in avg_acc]))\n",
    "#         # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = {\n",
    "    'vcl_100': 'VCL, [100]',\n",
    "    'vcl_100_coreset_50': 'VCL + coreset (50), [100]',\n",
    "    'vcl_100_coreset_100': 'VCL + coreset (100), [100]',\n",
    "    'vcl_100_100': 'VCL, [100, 100]',\n",
    "    'vcl_100_100_coreset_50': 'VCL + coreset (50), [100, 100]',\n",
    "    'vcl_100_100_coreset_100': 'VCL + coreset (100), [100, 100]',\n",
    "    'var_gp': 'VAR-GP',\n",
    "    'var_gp_block_diag': 'VAR-GP (Block Diagonal)',\n",
    "    'var_gp_mle_hypers': 'VAR-GP (MLE Hyperparameters)',\n",
    "    'var_gp_global': 'VAR-GP (Global)',\n",
    "    'var_gp_dkl_mlp': 'VAR-GP (DKL)'\n",
    "}\n",
    "\n",
    "def plot_test_acc(data, clist, name=None, xticks=None, loc='best'):\n",
    "    data.rename(columns=cmap, inplace=True)\n",
    "    \n",
    "    melt_data = data.melt(id_vars=['task'], value_vars=[cmap[k] for k in clist], var_name='Method', value_name='vals')\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(9,9))\n",
    "    sns.lineplot(ax=ax, data=melt_data, x='task', y='vals', hue='Method', marker='o',\n",
    "                 ci='sd', markersize=15, palette=sns.color_palette(\"tab10\", len(clist)))\n",
    "    ax.set_xlabel('Task', fontsize=30)\n",
    "    ax.set_ylabel('Test Accuracy', fontsize=30)\n",
    "    if xticks:\n",
    "        ax.set_xticks(xticks)\n",
    "    ax.legend(loc=loc, title='Method')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if name is not None:\n",
    "        # fig.savefig(name, bbox_inches='tight')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Accuracy Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('results/smnist.csv')\n",
    "\n",
    "plot_test_acc(data, ['var_gp', 'vcl_100_coreset_100', 'vcl_100_100_coreset_100'],\n",
    "              name='split_mnist.pdf')\n",
    "\n",
    "plot_test_acc(data, ['var_gp', 'var_gp_block_diag', 'var_gp_global', 'var_gp_mle_hypers'],\n",
    "              name='split_mnist_ep_mean_mle_hypers.pdf', loc='lower left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DKL Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('results/smnist.csv')\n",
    "plot_test_acc(data, ['var_gp', 'var_gp_dkl_mlp'],\n",
    "              name='split_mnist_dkl.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Inducing Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_inducing_pts(ckpt_dir):\n",
    "    for ckpt in range(5):\n",
    "        state_dict = torch.load(f'{ckpt_dir}/ckpt{ckpt}.pt', map_location=torch.device('cpu'))\n",
    "        z = state_dict.get('z')\n",
    "        N = 4\n",
    "        ind_pts_subset = z[2*ckpt:2*ckpt+2][:, torch.randperm(z.size(1))[:N], :].view(-1, N, 28, 28)\n",
    "        \n",
    "        fig, axes = plt.subplots(figsize=(5,10), nrows=N, ncols=2, sharey=True, sharex=True)\n",
    "        fig.subplots_adjust(wspace=-0.05, hspace=0.01)\n",
    "        for i in range(N):\n",
    "            for j in range(2):\n",
    "                axes[i, j].imshow(ind_pts_subset[j, i], interpolation='bilinear', cmap='gray')\n",
    "                axes[i, j].set_aspect('equal')\n",
    "                axes[i, j].grid(False)\n",
    "                axes[i, j].axis('off')\n",
    "\n",
    "        fig.suptitle(f'After Task {ckpt}', fontsize=50)\n",
    "\n",
    "        # fig.savefig(f'smnist_viz_{ckpt + 1}.pdf', bbox_inches='tight')\n",
    "\n",
    "# Add path to checkpoint directory.\n",
    "ckpt_dir = 'results/vargp-smnist'\n",
    "plot_inducing_pts(ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = 'results/vargp-smnist'\n",
    "ds = SplitMNIST('/tmp', train=False)\n",
    "\n",
    "acc_mat = []\n",
    "ent_mat = []\n",
    "\n",
    "prev_params = []\n",
    "for t in tqdm(range(5), desc='Train Task'):\n",
    "    mean_acc_list = []\n",
    "    mean_ent_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        cur_params = torch.load(f'{run_dir}/ckpt{t}.pt', map_location=device)\n",
    "        gp = VARGP.create_clf(ds, M=60, n_f=50, n_var_samples=20, prev_params=prev_params).to(device)\n",
    "        gp.load_state_dict(cur_params)\n",
    "\n",
    "        for task in tqdm(range(5), leave=False, desc='Test Task'):\n",
    "            ds.filter_by_class([2 * task, 2 * task + 1])\n",
    "\n",
    "            mean_acc, mean_ent = compute_acc_ent(ds, gp, batch_size=256, device=device)\n",
    "\n",
    "            mean_acc_list.append(mean_acc)\n",
    "            mean_ent_list.append(mean_ent)\n",
    "            \n",
    "    acc_mat.append(mean_acc_list)\n",
    "    ent_mat.append(mean_ent_list)\n",
    "    \n",
    "    ds.filter_by_class()\n",
    "    prev_params.append(cur_params)\n",
    "    \n",
    "\n",
    "acc_mat = torch.Tensor(acc_mat).numpy()\n",
    "norm_ent_mat = torch.Tensor(ent_mat).numpy() / np.log(10.0)\n",
    "\n",
    "# np.savez(f'{run_dir}/test_acc_and_ent.npz', acc=acc_mat, ent=norm_ent_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compute_bwt(acc_mat)"
   ]
  },
  {
   "source": [
    "### Predictive Entropy Matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_ent_mat = np.load('results/vargp-smnist/test_acc_and_ent.npz')['ent']\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10,5), nrows=1, ncols=2, sharex=True)\n",
    "sns.heatmap(ax=axes[0], data=norm_ent_mat, linewidths=2, cmap=sns.color_palette(\"summer\", as_cmap=True), cbar=False)\n",
    "axes[0].set_aspect('equal')\n",
    "axes[0].set_xlabel('Test Tasks')\n",
    "axes[0].set_ylabel('Train Tasks')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), fontsize=25)\n",
    "axes[0].set_yticklabels(axes[0].get_yticklabels(), fontsize=25)\n",
    "axes[0].set_title('VAR-GP (ours)')\n",
    "\n",
    "norm_ent_mat = np.load('results/vcl-smnist-seed1/test_acc_and_ent.npz')['ent']\n",
    "sns.heatmap(ax=axes[1], data=norm_ent_mat, linewidths=2, cmap=sns.color_palette(\"summer\", as_cmap=True), cbar=False)\n",
    "axes[1].set_aspect('equal')\n",
    "axes[1].set_xlabel('Test Tasks')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), fontsize=25)\n",
    "axes[1].set_yticklabels(axes[1].get_yticklabels(), fontsize=25)\n",
    "axes[1].set_title('VCL')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# fig.savefig(f'smnist_norm_entropy.pdf', bbox_inches='tight')"
   ]
  },
  {
   "source": [
    "### Varying Inducing Points"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('results/varying_M.csv')\n",
    "plot_data = pd.DataFrame({\n",
    "  'Test Accuracy': data.groupby(['M']).mean().to_numpy().flatten(),\n",
    "  'Task': np.repeat(np.expand_dims(np.arange(5), axis=0), 10, axis=0).flatten(),\n",
    "  'M': np.repeat(np.arange(20, 201, 20), 5)\n",
    "})\n",
    "plot_data = plot_data[plot_data['M'] > 20]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,9))\n",
    "sns.lineplot(ax=ax, data=plot_data, x='Task', y='Test Accuracy', hue='M', marker='o',\n",
    "             ci='sd', markersize=10, linewidth=3, alpha=.75, palette=sns.color_palette(\"tab10\", 9))\n",
    "ax.set_xlabel('Task', fontsize=30)\n",
    "ax.set_ylabel('Test Accuracy', fontsize=30)\n",
    "ax.legend(loc='best', title='$M$')\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig('smnist_varying_M.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permuted MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('results/pmnist.csv')\n",
    "\n",
    "plot_test_acc(data, ['var_gp', 'vcl_100_coreset_100', 'vcl_100_100_coreset_100'],\n",
    "              name='permuted_mnist.pdf', xticks=range(10))\n",
    "\n",
    "plot_test_acc(data, ['var_gp', 'var_gp_block_diag', 'var_gp_global', 'var_gp_mle_hypers'],\n",
    "              name='permuted_mnist_ep_mean_mle_hypers.pdf', xticks=range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(1)\n",
    "tasks = [torch.arange(784)] + PermutedMNIST.create_tasks(n=9)\n",
    "\n",
    "run_dir = 'results/vargp-pmnist-seed1'\n",
    "ds = PermutedMNIST('/tmp', train=False)\n",
    "\n",
    "acc_mat = []\n",
    "ent_mat = []\n",
    "\n",
    "prev_params = []\n",
    "for t in tqdm(range(10), desc='Train Task'):\n",
    "    mean_acc_list = []\n",
    "    mean_ent_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        cur_params = torch.load(f'{run_dir}/ckpt{t}.pt', map_location=device)\n",
    "        gp = VARGP.create_clf(ds, M=100, n_f=50, n_var_samples=20, prev_params=prev_params).to(device)\n",
    "        gp.load_state_dict(cur_params)\n",
    "\n",
    "        for i, task in tqdm(enumerate(tasks), leave=False, desc='Test Task'):\n",
    "            ds = PermutedMNIST('/tmp', train=False)\n",
    "            ds.set_task(task)\n",
    "  \n",
    "            mean_acc, mean_ent = compute_acc_ent(ds, gp, batch_size=256, device=device)\n",
    "\n",
    "            mean_acc_list.append(mean_acc)\n",
    "            mean_ent_list.append(mean_ent)\n",
    "            \n",
    "    acc_mat.append(mean_acc_list)\n",
    "    ent_mat.append(mean_ent_list)\n",
    "\n",
    "    prev_params.append(cur_params)\n",
    "\n",
    "\n",
    "acc_mat = torch.Tensor(acc_mat).numpy()\n",
    "norm_ent_mat = torch.Tensor(ent_mat).numpy() / np.log(10.0)\n",
    "\n",
    "# np.savez(f'{run_dir}/test_acc_and_ent.npz', acc=acc_mat, ent=ent_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_bwt(acc_mat)"
   ]
  },
  {
   "source": [
    "### Predictive Entropy Matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_ent_mat = np.load('results/vargp-pmnist-seed1/test_acc_and_ent.npz')['ent']\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10,5), nrows=1, ncols=2, sharex=True)\n",
    "sns.heatmap(ax=axes[0], data=norm_ent_mat, linewidths=2, cmap=sns.color_palette(\"summer\", as_cmap=True), cbar=False)\n",
    "axes[0].set_aspect('equal')\n",
    "axes[0].set_xlabel('Test Tasks')\n",
    "axes[0].set_ylabel('Train Tasks')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), fontsize=25)\n",
    "axes[0].set_yticklabels(axes[0].get_yticklabels(), fontsize=25)\n",
    "axes[0].set_title('VAR-GP (ours)')\n",
    "\n",
    "norm_ent_mat = np.load('results/vcl-pmnist-seed1/test_acc_and_ent.npz')['ent']\n",
    "sns.heatmap(ax=axes[1], data=norm_ent_mat, linewidths=2, cmap=sns.color_palette(\"summer\", as_cmap=True), cbar=False)\n",
    "axes[1].set_aspect('equal')\n",
    "axes[1].set_xlabel('Test Tasks')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), fontsize=25)\n",
    "axes[1].set_yticklabels(axes[1].get_yticklabels(), fontsize=25)\n",
    "axes[1].set_title('VCL')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# fig.savefig('pmnist_norm_entropy.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "name": "python394jvsc74a57bd0f6f4ef2e4dfc72dba41423bb399455b0e2be86e7ec916ab82ad022c9707621b9",
   "display_name": "Python 3.9.4 64-bit ('var-gp': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}